{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a6b5268",
   "metadata": {},
   "source": [
    "# ODS_project\n",
    "### Optimization Methods for Recommender Systems\n",
    "#### Rebecca Esegio, Giacomo Filippin, Emma Lovato\n",
    "2130576, Lovato Emma, emma.lovato@studenti.unipd.it\n",
    "\n",
    "2144564, Rebecca Esegio, rebecca.esegio@studenti.unipd.it\n",
    "\n",
    "2130958, Giacomo Filippin, giacomo.filippin@studenti.unipd.it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06521a7",
   "metadata": {},
   "source": [
    "## Understanding the Problem & Theoretical Foundations\n",
    "The goal is to implement and compare three variants of the Frank-Wolfe algorithm for a Matrix Completion problem, a key application in recommender systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca2769c",
   "metadata": {},
   "source": [
    "### The Matrix Completion Problem\n",
    "\n",
    "We want to recover a matrix $X \\in \\mathbb{R}^{m \\times n}$ (e.g., user ratings for movies) from which we only observe a small subset of entries. The key assumption is that the original matrix is **low-rank**. The problem can be formulated as follows:\n",
    "\n",
    "$$\n",
    "\\min_{X \\in \\mathbb{R}^{m \\times n}} f(X) := \\sum_{(i,j) \\in J} (X_{ij} - U_{ij})^2 \\quad \\text{s.t.} \\quad \\text{rank}(X) \\le \\delta\n",
    "$$\n",
    "\n",
    "where $U$ is the matrix of observed ratings, $J$ is the set of known rating indices, and $\\delta$ is the desired maximum rank. Since the rank constraint is non-convex and hard to handle, a convex relaxation is used, constraining the **nuclear norm** (the sum of the singular values) of the matrix:\n",
    "\n",
    "$$\n",
    "\\min_{X \\in \\mathbb{R}^{m \\times n}} f(X) := \\sum_{(i,j) \\in J} (X_{ij} - U_{ij})^2 \\quad \\text{s.t.} \\quad \\|X\\|_* \\le \\tau\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1939654",
   "metadata": {},
   "source": [
    "### Objective Function:\n",
    " $f(X)$ is a quadratic function, hence it is convex and differentiable. Its gradient is:\n",
    "    $$\n",
    "    \\nabla f(X) = 2(X - U)_J\n",
    "    $$\n",
    "    where $(A)_J$ is a matrix that has the same values as $A$ on the indices $J$ and is zero elsewhere.\n",
    "\n",
    "### Feasible Domain:\n",
    "The domain $C = \\{X \\in \\mathbb{R}^{m \\times n} : \\|X\\|_* \\le \\tau\\}$ is the nuclear norm ball. It is a compact and convex set. Crucially, it is the convex hull of rank-1 matrices:\n",
    "    $$\n",
    "    C = \\text{conv}\\{\\tau \\mathbf{u}\\mathbf{v}^T : \\mathbf{u} \\in \\mathbb{R}^m, \\mathbf{v} \\in \\mathbb{R}^n, \\|\\mathbf{u}\\|_2 = \\|\\mathbf{v}\\|_2 = 1\\}\n",
    "    $$\n",
    "    These rank-1 elements, $\\tau \\mathbf{u}\\mathbf{v}^T$, are the **atoms** of our domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646a9395",
   "metadata": {},
   "source": [
    "### Key Algorithm Components\n",
    "\n",
    "All the Frank-Wolfe algorithms we will implement share two fundamental components: the Linear Minimization Oracle (LMO) and the Line Search.\n",
    "\n",
    "**a) Linear Minimization Oracle (LMO)**\n",
    "\n",
    "At each iteration $k$, the FW algorithm must solve the following linearized subproblem:\n",
    "$$\n",
    "\\mathbf{s}_k = \\text{arg min}_{\\mathbf{s} \\in C} \\langle \\mathbf{s}, \\nabla f(\\mathbf{X}^{(k)}) \\rangle\n",
    "$$\n",
    "For our domain (the nuclear norm ball), the solution to this problem is found by computing the top singular vector pair of the matrix $\\nabla f(\\mathbf{X}^{(k)})$. If $\\mathbf{u}_1, \\mathbf{v}_1$ are the left and right singular vectors corresponding to the largest singular value of $\\nabla f(\\mathbf{X}^{(k)})$, then the solution is:\n",
    "$$\n",
    "\\mathbf{s}_k = -\\tau \\cdot \\mathbf{u}_1 \\mathbf{v}_1^T\n",
    "$$\n",
    "This computation (1-SVD) is much more efficient than a full SVD, especially since the gradient is sparse.\n",
    "\n",
    "Why We Use SVD? \n",
    "In short: We use the SVD because it is the mathematical tool that solves the Linear Minimization Oracle (LMO) when our feasible set is the nuclear norm ball.\n",
    "\n",
    "**b) Line Search for the Optimal Step $\\gamma$**\n",
    "\n",
    "Once we find a search direction $\\mathbf{d}_k$, we must choose a step-size $\\gamma_k \\in [0, \\gamma_{max}]$ to update the solution: $\\mathbf{X}^{(k+1)} = \\mathbf{X}^{(k)} + \\gamma_k \\mathbf{d}_k$. [cite_start]Instead of using a fixed or diminishing step-size like $\\gamma_k = \\frac{2}{k+2}$ [cite: 429][cite_start], we can compute the optimal one with an exact line search, which for a quadratic objective function has an efficient, closed-form solution.\n",
    "\n",
    "We need to minimize $\\phi(\\gamma) = f(\\mathbf{X}^{(k)} + \\gamma \\mathbf{d}_k)$ with respect to $\\gamma$:\n",
    "$$\n",
    "\\phi(\\gamma) = \\|P_J(\\mathbf{X}^{(k)} + \\gamma \\mathbf{d}_k) - P_J(U)\\|_F^2 = \\| (P_J(\\mathbf{X}^{(k)}) - P_J(U)) + \\gamma P_J(\\mathbf{d}_k) \\|_F^2\n",
    "$$\n",
    "This is a parabola in $\\gamma$. To find the minimum, we set its derivative $\\phi'(\\gamma)$ to zero:\n",
    "$$\n",
    "\\phi'(\\gamma) = 2 \\langle P_J(\\mathbf{X}^{(k)}) - P_J(U), P_J(\\mathbf{d}_k) \\rangle_F + 2\\gamma \\|P_J(\\mathbf{d}_k)\\|_F^2 = 0\n",
    "$$\n",
    "Recalling that $\\nabla f(\\mathbf{X}^{(k)}) = 2 P_J(\\mathbf{X}^{(k)} - U)$, we get:\n",
    "$$\n",
    "\\gamma^* = - \\frac{\\langle \\nabla f(\\mathbf{X}^{(k)}), P_J(\\mathbf{d}_k) \\rangle_F}{2 \\|P_J(\\mathbf{d}_k)\\|_F^2}\n",
    "$$\n",
    "The final step-size will be $\\gamma_k = \\text{max}(0, \\text{min}(\\gamma_{max}, \\gamma^*))$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3126bbf8",
   "metadata": {},
   "source": [
    "### Understanding the Nuclear Norm Ball and Its Role in the Project\n",
    "\n",
    "The **nuclear norm ball** is a central concept in this project. It serves as the feasible set for our optimization problem and is the primary reason why the Frank-Wolfe algorithm is such an effective tool for Matrix Completion. This section explains what it is and why it's so important.\n",
    "\n",
    "#### 1. The Simple, Direct Definition\n",
    "\n",
    "Simply put, the nuclear norm ball is a \"container\" for matrices. It is defined by two components:\n",
    "\n",
    "* **The Nuclear Norm ($||X||_*$):** This is the sum of all the singular values of a matrix $X$. The singular values ($\\sigma_i$) can be thought of as measuring the magnitude of the matrix in different principal directions. \n",
    "    $$\n",
    "    \\|X\\|_* = \\sum_i \\sigma_i(X)\n",
    "    $$\n",
    "\n",
    "* **A Ball:** Like a standard Euclidean ball which contains all vectors with a norm less than a certain radius, the nuclear norm ball is the set of all matrices $X$ whose nuclear norm is less than or equal to a specified radius, $\\tau$. \n",
    "\n",
    "Formally, the nuclear norm ball $C$ is the set:\n",
    "$$\n",
    "C = \\{X \\in \\mathbb{R}^{m \\times n} : \\|X\\|_* \\le \\tau \\}\n",
    "$$\n",
    "\n",
    "#### 2. Why It's Crucial for Matrix Completion\n",
    "\n",
    "The core goal of Matrix Completion is to find a **low-rank** matrix that fits the observed data.  The rank of a matrix is the number of non-zero singular values. However, directly constraining the rank (e.g., $\\text{rank}(X) \\le \\delta$) results in a non-convex, computationally intractable optimization problem. \n",
    "\n",
    "This is where the nuclear norm becomes essential. It serves as a **convex relaxation** for the rank function.  The intuition comes from a powerful analogy with vectors and sparsity:\n",
    "\n",
    "* **For Vectors (Sparsity):** In problems like LASSO, the **$l_1$ norm** ($\\|\\mathbf{v}\\|_1 = \\sum_i |v_i|$) is used as a penalty or constraint. It is well-known that minimizing the $l_1$ norm encourages solutions where many vector components are exactly zero, thus enforcing **sparsity**.\n",
    "\n",
    "* **For Matrices (Low-Rank):** The **nuclear norm** is the matrix equivalent of the $l_1$ norm. By minimizing the sum of singular values, it encourages solutions where many singular values are zero. This enforces **low-rankness**.\n",
    "\n",
    "Therefore, by constraining our solution $X$ to lie within a nuclear norm ball ($\\|X\\|_* \\le \\tau$), we are using a computationally feasible method to enforce the underlying assumption that the matrix we are looking for is low-rank.\n",
    "\n",
    "#### 3. The Connection to the Frank-Wolfe Algorithm\n",
    "\n",
    "The Frank-Wolfe algorithm is exceptionally well-suited for optimizing over the nuclear norm ball due to its geometric properties.\n",
    "\n",
    "* **The \"Atoms\" are Rank-1 Matrices:** The extreme points (the \"corners\" or \"atoms\") of the nuclear norm ball are all **rank-1 matrices**.  Specifically, the feasible set $C$ is the convex hull of all rank-1 matrices with a nuclear norm of $\\tau$. \n",
    "\n",
    "* **The LMO Finds the Best Rank-1 Matrix:** At each iteration, the Frank-Wolfe Linear Minimization Oracle (LMO) solves for the atom that best aligns with the negative gradient. For this problem, this means the LMO finds the optimal **rank-1 matrix** to move towards. \n",
    "\n",
    "* **Frank-Wolfe Naturally Builds a Low-Rank Solution:** Because the algorithm constructs its solution as a convex combination of the atoms it has found, the resulting matrix is inherently a sum of a few rank-1 matrices. This means the solution produced by Frank-Wolfe is naturally **low-rank**, perfectly aligning with the goal of the Matrix Completion problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20594f5",
   "metadata": {},
   "source": [
    "## Python implementation\n",
    "Let's translate the theory into code. We will create a modular structure to easily assemble the three algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.sparse import csc_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import your custom modules\n",
    "from functions import MatrixCompletionProblem\n",
    "from algorithms import frank_wolfe_solver, away_step_frank_wolfe_solver, pairwise_frank_wolfe_solver\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e0ada5",
   "metadata": {},
   "source": [
    "## Data Selection and Preparation\n",
    "Three datasets:\n",
    "1. MovieLens 2M\n",
    "2. Jester Dataset 2 ?\n",
    "3. Book-Crossings ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76420119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MovieLens 2M dataset\n",
    "df_ratings=pd.read_csv('./rating.csv')\n",
    "\n",
    "reviews_groups = df_ratings.groupby(\"rating\")[\"rating\"].count()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(reviews_groups.index, reviews_groups.values, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Ratings Distribution\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(reviews_groups.index)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48838498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movielens_100k(path_to_data='ml-100k/u.data'):\n",
    "    \"\"\"Loads and prepares the MovieLens 100k dataset.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path_to_data, sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "    except FileNotFoundError:\n",
    "        print(\"Dataset not found. Please download MovieLens 100K and place u.data in a 'ml-100k' folder.\")\n",
    "        print(\"Download from: https://grouplens.org/datasets/movielens/100k/\")\n",
    "        return None, None\n",
    "\n",
    "    user_map = {uid: i for i, uid in enumerate(df['user_id'].unique())}\n",
    "    item_map = {iid: i for i, iid in enumerate(df['item_id'].unique())}\n",
    "    \n",
    "    df['user_idx'] = df['user_id'].map(user_map)\n",
    "    df['item_idx'] = df['item_id'].map(item_map)\n",
    "    \n",
    "    num_users, num_items = len(user_map), len(item_map)\n",
    "    \n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_matrix = csc_matrix((train_df['rating'], (train_df['user_idx'], train_df['item_idx'])), shape=(num_users, num_items))\n",
    "    test_matrix = csc_matrix((test_df['rating'], (test_df['user_idx'], test_df['item_idx'])), shape=(num_users, num_items))\n",
    "                                     \n",
    "    return train_matrix, test_matrix\n",
    "\n",
    "# Load the data\n",
    "train_data, test_data = load_movielens_100k()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca58dc31",
   "metadata": {},
   "source": [
    "## Running Experiments and Analyzing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216c8f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the problem with the training data\n",
    "mc_problem = MatrixCompletionProblem(train_data)\n",
    "\n",
    "# --- Experiment Parameters ---\n",
    "TAU = 5000.0  # This is a hyperparameter to tune\n",
    "MAX_ITER = 100\n",
    "\n",
    "solvers_to_run = {\n",
    "    \"Classic Frank-Wolfe\": frank_wolfe_solver,\n",
    "    \"Away-Step Frank-Wolfe\": away_step_frank_wolfe_solver,\n",
    "    \"Pairwise Frank-Wolfe\": pairwise_frank_wolfe_solver\n",
    "}\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c1ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, solver_func in solvers_to_run.items():\n",
    "    start_time = time.time()\n",
    "    solution_X, history = solver_func(mc_problem, tau=TAU, max_iter=MAX_ITER)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    results[name] = {\n",
    "        \"solution\": solution_X,\n",
    "        \"history\": history,\n",
    "        \"time\": end_time - start_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861eccb1",
   "metadata": {},
   "source": [
    "### Plot convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ad377",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "for name, result in results.items():\n",
    "    plt.plot(result['history'], label=f\"{name} (time: {result['time']:.2f}s)\", lw=2)\n",
    "\n",
    "plt.xlabel(\"Iteration\", fontsize=12)\n",
    "plt.ylabel(\"Objective Function (Training MSE)\", fontsize=12)\n",
    "plt.title(\"Convergence of Frank-Wolfe Variants on MovieLens 100K\", fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, which='both', linestyle='--')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c62618",
   "metadata": {},
   "source": [
    "## Analyze Results and Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the others datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ee5697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the results\n",
    "summary_data = []\n",
    "\n",
    "# Create a problem instance for the test set to calculate RMSE\n",
    "test_problem = MatrixCompletionProblem(test_data)\n",
    "num_test_ratings = len(test_data.data)\n",
    "\n",
    "for name, result in results.items():\n",
    "    final_train_error = result['history'][-1]\n",
    "    \n",
    "    # Calculate Test RMSE\n",
    "    test_mse = test_problem.objective_function(result['solution'])\n",
    "    test_rmse = np.sqrt(test_mse / num_test_ratings) if num_test_ratings > 0 else 0\n",
    "    \n",
    "    summary_data.append({\n",
    "        \"Algorithm\": name,\n",
    "        \"Final Training MSE\": final_train_error,\n",
    "        \"Test RMSE\": test_rmse,\n",
    "        \"Time (s)\": result['time']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n--- Experiment Summary ---\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
